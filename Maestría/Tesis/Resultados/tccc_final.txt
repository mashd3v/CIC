Conjunto de prueba para la etiqueta toxic
Predicción del modelo sobre el conjunto de prueba
              precision    recall  f1-score   support

           0       0.99      0.91      0.95     14478
           1       0.50      0.91      0.65      1480

    accuracy                           0.91     15958
   macro avg       0.75      0.91      0.80     15958
weighted avg       0.94      0.91      0.92     15958

Conjunto de prueba para la etiqueta severe_toxic
Predicción del modelo sobre el conjunto de prueba
              precision    recall  f1-score   support

           0       1.00      0.94      0.97     15810
           1       0.12      0.86      0.22       148

    accuracy                           0.94     15958
   macro avg       0.56      0.90      0.59     15958
weighted avg       0.99      0.94      0.96     15958

Conjunto de prueba para la etiqueta obscene
Predicción del modelo sobre el conjunto de prueba
              precision    recall  f1-score   support

           0       1.00      0.94      0.97     15122
           1       0.46      0.93      0.61       836

    accuracy                           0.94     15958
   macro avg       0.73      0.93      0.79     15958
weighted avg       0.97      0.94      0.95     15958

Conjunto de prueba para la etiqueta threat
Predicción del modelo sobre el conjunto de prueba
              precision    recall  f1-score   support

           0       1.00      0.91      0.95     15921
           1       0.02      0.95      0.05        37

    accuracy                           0.91     15958
   macro avg       0.51      0.93      0.50     15958
weighted avg       1.00      0.91      0.95     15958

Conjunto de prueba para la etiqueta insult
Predicción del modelo sobre el conjunto de prueba
              precision    recall  f1-score   support

           0       1.00      0.92      0.96     15167
           1       0.38      0.92      0.54       791

    accuracy                           0.92     15958
   macro avg       0.69      0.92      0.75     15958
weighted avg       0.97      0.92      0.94     15958

Conjunto de prueba para la etiqueta identity_hate
Predicción del modelo sobre el conjunto de prueba
              precision    recall  f1-score   support

           0       1.00      0.89      0.94     15811
           1       0.07      0.90      0.13       147

    accuracy                           0.89     15958
   macro avg       0.54      0.90      0.54     15958
weighted avg       0.99      0.89      0.93     15958

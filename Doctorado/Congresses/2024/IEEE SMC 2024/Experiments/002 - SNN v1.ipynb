{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting emotions in Spanish lyrics songs: Vanilla SNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wget' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mwget\u001b[49m \u001b[38;5;241m-\u001b[39mV\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wget' is not defined"
     ]
    }
   ],
   "source": [
    "wget -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: https://pln.inf.um.es/corpora/emospeech/2024/dataset/download/train?api_key=25414fffb668b475f0b5ce01d3b37d25\n",
      "zsh:1: no matches found: https://pln.inf.um.es/corpora/emospeech/2024/dataset/download/test?api_key=25414fffb668b475f0b5ce01d3b37d25\n",
      "zsh:1: command not found: wget\n",
      "zsh:1: command not found: wget\n"
     ]
    }
   ],
   "source": [
    "!wget https://pln.inf.um.es/corpora/emospeech/2024/dataset/download/train?api_key=25414fffb668b475f0b5ce01d3b37d25 -O segments_train.zip\n",
    "!wget https://pln.inf.um.es/corpora/emospeech/2024/dataset/download/test?api_key=25414fffb668b475f0b5ce01d3b37d25 -O segments_test.zip\n",
    "\n",
    "!wget https://pln.inf.um.es/corpora/emospeech/2024/EmoSPeech_phase_2_train_public.csv\n",
    "!wget https://pln.inf.um.es/corpora/emospeech/2024/EmoSPeech_phase_2_test_public.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    /var/folders/d9/9kxdpj_1093dfyt04_xwd8v80000gn/T/ipykernel_46811/2243671251.py:19: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('retina')\n",
      " [py.warnings]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import brian2 as b2\n",
    "from brian2 import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Vectorizadores\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# descarga las stopwords en espaÃ±ol y guardalas en una lista\n",
    "from nltk.corpus import stopwords\n",
    "import string \n",
    "from nltk.tokenize import word_tokenize\n",
    "stopwords = set(stopwords.words('spanish'))\n",
    "\n",
    "\n",
    "# Grafica en formato retina\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(train_data, test_data, min_df, ngrams, stop_words_lang):\n",
    "    # Vectorizar texto\n",
    "    vectorizer = TfidfVectorizer(min_df=min_df, \n",
    "                                ngram_range=ngrams, \n",
    "                                stop_words=stop_words_lang)\n",
    "    tfidf_train = vectorizer.fit_transform(train_data).toarray()\n",
    "    tfidf_test = [vectorizer.transform(subset).toarray() for subset in test_data]\n",
    "    \n",
    "    return vectorizer, tfidf_train, tfidf_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brian2 import *\n",
    "\n",
    "def initialize_supervised_model(n_features, n_classes=3):\n",
    "    start_scope()\n",
    "    \n",
    "    # Define parameters\n",
    "    tau_pre = 20*ms\n",
    "    tau_post = 20*ms\n",
    "    w_max = 0.3\n",
    "    w_min = 0.0\n",
    "    A_pre = 0.01\n",
    "    A_post = -0.01\n",
    "    tau = 20*ms\n",
    "    vr = -70*mV\n",
    "    vt = -50*mV\n",
    "    learning_rate = 0.01\n",
    "    \n",
    "    eqs = '''\n",
    "    dv/dt = (0.04*v**2 + 5*v + 140 - u + I) / tau : volt\n",
    "    du/dt = (a*(b*v - u)) / tau : volt\n",
    "    I : volt\n",
    "    a : 1\n",
    "    b : 1\n",
    "    c : volt\n",
    "    d : volt\n",
    "    '''\n",
    "    \n",
    "    # Define neuron groups\n",
    "    G = NeuronGroup(n_classes, eqs, threshold='v > vt', reset='v = c; u += d', method='euler')\n",
    "    G.a = 0.02\n",
    "    G.b = 0.2\n",
    "    G.c = -65*mV\n",
    "    G.d = 8*mV\n",
    "\n",
    "    # Define TimedArray for dynamic rates and PoissonGroup\n",
    "    rate_array = TimedArray(np.zeros(n_features), dt=1*ms)  # Placeholder array\n",
    "    P = PoissonGroup(n_features, rates='rate_array(t, i)')\n",
    "\n",
    "    # Define synapses\n",
    "    S = Synapses(P, G,\n",
    "                 '''\n",
    "                 w : 1\n",
    "                 dapre/dt = -apre/tau_pre : 1 (event-driven)\n",
    "                 dapost/dt = -apost/tau_post : 1 (event-driven)\n",
    "                 ''',\n",
    "                 on_pre='''\n",
    "                 I_post += w * mV\n",
    "                 apre += A_pre\n",
    "                 w = clip(w + (apost - learning_rate*(target - 1)), w_min, w_max)\n",
    "                 ''',\n",
    "                 on_post='''\n",
    "                 apost += A_post\n",
    "                 w = clip(w + (apre + learning_rate*(target - 0)), w_min, w_max)\n",
    "                 ''')\n",
    "    \n",
    "    S.connect()\n",
    "    S.w = 'rand() * 0.1'\n",
    "    \n",
    "    model = {\n",
    "        'neuron_group': G,\n",
    "        'input_group': P,\n",
    "        'synapses': S,\n",
    "        'rate_array': rate_array  # Add rate_array to the model dict\n",
    "    }\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, tfidf_matrix, sim_time=100*ms):\n",
    "    \"\"\"\n",
    "    Train the SNN model on a given TF-IDF matrix where each row is an input document.\n",
    "    Args:\n",
    "    - model: The SNN model components.\n",
    "    - tfidf_matrix: The input TF-IDF matrix.\n",
    "    - sim_time: The simulation time for each document.\n",
    "\n",
    "    Returns:\n",
    "    - Updated model after training.\n",
    "    \"\"\"\n",
    "    for document_vector in tfidf_matrix:\n",
    "        model['input_group'].rates = document_vector * Hz\n",
    "        run(sim_time)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_supervised_model(model, tfidf_matrix, labels, sim_time=50*ms):\n",
    "    \"\"\"\n",
    "    Train the SNN model using supervised learning. This includes dynamically updating the input rates and handling the target labels for supervised STDP.\n",
    "    \"\"\"\n",
    "    # Check that the duration of the TimedArray matches or exceeds the simulation time\n",
    "    duration = len(tfidf_matrix) * sim_time\n",
    "    timestep = sim_time / len(tfidf_matrix)  # Simplified timestep assumption\n",
    "    model['rate_array'] = TimedArray(np.zeros((len(tfidf_matrix), model['input_group'].N)) * Hz, dt=timestep)\n",
    "    \n",
    "    for idx, (document_vector, label) in enumerate(zip(tfidf_matrix, labels)):\n",
    "        # Update the rates in the TimedArray for the current step\n",
    "        model['rate_array'].values[idx, :] = document_vector * Hz\n",
    "        \n",
    "        # Define target logic and update the synapses namespace for supervised learning\n",
    "        target = np.zeros(model['neuron_group'].N)\n",
    "        target[label] = 1\n",
    "        model['synapses'].namespace['target'] = target  # This should be reflected in synapse equations if 'target' is used there\n",
    "\n",
    "        # Run the simulation for the specified time\n",
    "        run(sim_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, n_features, tfidf_vector, sim_time=50*ms):\n",
    "    \"\"\"\n",
    "    Predict the class of a new document by temporarily creating a PoissonGroup and Synapses with the provided tfidf_vector.\n",
    "    \"\"\"\n",
    "    # Ensure tfidf_vector is a 1D array matching n_features\n",
    "    if tfidf_vector.ndim > 1:\n",
    "        tfidf_vector = tfidf_vector.flatten()\n",
    "\n",
    "    # Create a temporary PoissonGroup with rates set from the tfidf_vector\n",
    "    temp_input_group = PoissonGroup(n_features, rates=tfidf_vector * Hz)\n",
    "    \n",
    "    # Create temporary synapses with the same parameters as the original model, explicitly stating synaptic model and actions\n",
    "    temp_synapses = Synapses(temp_input_group, model['neuron_group'],\n",
    "                             model['synapses'].model,\n",
    "                             on_pre=model['synapses'].pre.code,  # Use the actual code strings or define explicitly if not available\n",
    "                             on_post=model['synapses'].post.code)  # Same here\n",
    "    temp_synapses.connect()\n",
    "    temp_synapses.w = model['synapses'].w  # Copy weights from the trained model\n",
    "    \n",
    "    # Run the simulation with the temporary setup\n",
    "    run(sim_time)\n",
    "    \n",
    "    # Determine the class by the neuron with the highest spike count\n",
    "    spike_counts = [np.sum(model['neuron_group'].v[i] > model['neuron_group'].vt) for i in range(model['neuron_group'].N)]\n",
    "    predicted_class = np.argmax(spike_counts)\n",
    "    \n",
    "    return predicted_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_tfidf_vectors(tfidf_matrix):\n",
    "    \"\"\"\n",
    "    Normaliza los vectores TF-IDF para que estÃ©n en una escala adecuada para\n",
    "    ser utilizados como tasas de disparo en una red de neuronas de Poisson.\n",
    "    \"\"\"\n",
    "    tfidf_matrix = np.array(tfidf_matrix)\n",
    "    normalized = (tfidf_matrix - np.min(tfidf_matrix)) / (np.max(tfidf_matrix) - np.min(tfidf_matrix)) * 255\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../Data/Spanish_songs_lyrics.csv'\n",
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emocion\n",
       "N    2211\n",
       "P    2140\n",
       "S    1606\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.emocion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide las canciones en X_train, y_train, X_test y y_test con un 80/20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['fragmento'], \n",
    "                                                    data['emocion'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_esp = list(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    /var/folders/d9/9kxdpj_1093dfyt04_xwd8v80000gn/T/ipykernel_46811/3083546973.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  normalized = (tfidf_matrix - np.min(tfidf_matrix)) / (np.max(tfidf_matrix) - np.min(tfidf_matrix)) * 255\n",
      " [py.warnings]\n"
     ]
    }
   ],
   "source": [
    "vectorizer_train, tfidf_train, tfidf_test = vectorize_text(train_data=X_train, \n",
    "                                                           test_data=[X_test], \n",
    "                                                           min_df=2, \n",
    "                                                           ngrams=(1, 2), \n",
    "                                                           stop_words_lang=stop_words_esp)\n",
    "train_normalized, test_normalized = [], []\n",
    "for tfidf in tfidf_train:\n",
    "    train_normalized.append(normalize_tfidf_vectors(tfidf))\n",
    "\n",
    "for tfidf in tfidf_test:\n",
    "    test_normalized.append(normalize_tfidf_vectors(tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example initialization and usage\n",
    "n_features = tfidf_train.shape[1]\n",
    "model = initialize_supervised_model(n_features=n_features, \n",
    "                                    n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_labels(labels):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    \"\"\"Encode text labels into integers.\"\"\"\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(labels)\n",
    "    return le, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example TF-IDF data and labels\n",
    "tfidf_matrix = train_normalized\n",
    "re, labels = prepare_labels(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "train_supervised_model(model, tfidf_matrix, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "No attribute with name model",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/brian2/groups/group.py:379\u001b[0m, in \u001b[0;36mVariableOwner.state\u001b[0;34m(self, name, use_units, level)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/brian2/core/variables.py:1611\u001b[0m, in \u001b[0;36mVariables.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[0;32m-> 1611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variables\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'model'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/brian2/groups/group.py:417\u001b[0m, in \u001b[0;36mVariableOwner.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    416\u001b[0m         use_units \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_units\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/brian2/groups/group.py:381\u001b[0m, in \u001b[0;36mVariableOwner.state\u001b[0;34m(self, name, use_units, level)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m--> 381\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mState variable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_units:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'State variable model not found.'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example prediction\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m predicted_class \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mn_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtfidf_vector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_normalized\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Class:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predicted_class)\n",
      "Cell \u001b[0;32mIn[86], line 14\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(model, n_features, tfidf_vector, sim_time)\u001b[0m\n\u001b[1;32m     10\u001b[0m temp_input_group \u001b[38;5;241m=\u001b[39m PoissonGroup(n_features, rates\u001b[38;5;241m=\u001b[39mtfidf_vector \u001b[38;5;241m*\u001b[39m Hz)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Create temporary synapses with the same parameters as the original model, explicitly stating synaptic model and actions\u001b[39;00m\n\u001b[1;32m     13\u001b[0m temp_synapses \u001b[38;5;241m=\u001b[39m Synapses(temp_input_group, model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneuron_group\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m---> 14\u001b[0m                          \u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msynapses\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m,\n\u001b[1;32m     15\u001b[0m                          on_pre\u001b[38;5;241m=\u001b[39mmodel[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msynapses\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mpre\u001b[38;5;241m.\u001b[39mcode,  \u001b[38;5;66;03m# Use the actual code strings or define explicitly if not available\u001b[39;00m\n\u001b[1;32m     16\u001b[0m                          on_post\u001b[38;5;241m=\u001b[39mmodel[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msynapses\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mpost\u001b[38;5;241m.\u001b[39mcode)  \u001b[38;5;66;03m# Same here\u001b[39;00m\n\u001b[1;32m     17\u001b[0m temp_synapses\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[1;32m     18\u001b[0m temp_synapses\u001b[38;5;241m.\u001b[39mw \u001b[38;5;241m=\u001b[39m model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msynapses\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mw  \u001b[38;5;66;03m# Copy weights from the trained model\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/brian2/groups/group.py:420\u001b[0m, in \u001b[0;36mVariableOwner.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate(name, use_units)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo attribute with name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: No attribute with name model"
     ]
    }
   ],
   "source": [
    "# Example prediction\n",
    "predicted_class = predict(model=model, \n",
    "                        n_features=n_features,\n",
    "                        tfidf_vector=test_normalized[0][0])\n",
    "print(\"Predicted Class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brian2 import *\n",
    "\n",
    "def initialize_supervised_model(n_features, n_classes=3):\n",
    "    start_scope()\n",
    "\n",
    "    # Neuron and synaptic parameters\n",
    "    tau_pre = 20*ms\n",
    "    tau_post = 20*ms\n",
    "    w_max = 0.3\n",
    "    w_min = 0.0\n",
    "    A_pre = 0.01\n",
    "    A_post = -0.01\n",
    "    tau = 20*ms\n",
    "    vr = -70*mV\n",
    "    vt = -50*mV\n",
    "\n",
    "    # Izhikevich model equations\n",
    "    eqs = '''\n",
    "    dv/dt = (0.04*v**2 + 5*v + 140 - u + I) / tau : volt\n",
    "    du/dt = (a*(b*v - u)) / tau : volt\n",
    "    I : volt\n",
    "    a : 1\n",
    "    b : 1\n",
    "    c : volt\n",
    "    d : volt\n",
    "    '''\n",
    "\n",
    "    G = NeuronGroup(n_classes, eqs, threshold='v > vt', reset='v = c; u += d', method='euler')\n",
    "    G.a = 0.02\n",
    "    G.b = 0.2\n",
    "    G.c = -65*mV\n",
    "    G.d = 8*mV\n",
    "\n",
    "    rate_array = TimedArray(np.zeros((1, n_features)) * Hz, dt=1*ms)\n",
    "    P = PoissonGroup(n_features, rates='rate_array(t, i)')\n",
    "\n",
    "    # Synapses with reward-modulated STDP\n",
    "    S = Synapses(P, G,\n",
    "                 '''\n",
    "                 w : 1\n",
    "                 dapre/dt = -apre/tau_pre : 1 (event-driven)\n",
    "                 dapost/dt = -apost/tau_post : 1 (event-driven)\n",
    "                 target : integer (constant over runs)\n",
    "                 ''',\n",
    "                 on_pre='''\n",
    "                 I_post += w * mV\n",
    "                 apre += A_pre\n",
    "                 w = clip(w + (target == i_post) * A_post, w_min, w_max)\n",
    "                 ''',\n",
    "                 on_post='''\n",
    "                 apost += A_post\n",
    "                 w = clip(w + (target == i_post) * A_pre, w_min, w_max)\n",
    "                 ''')\n",
    "    S.connect()\n",
    "    S.w = 'rand() * w_max'\n",
    "    \n",
    "    model = {\n",
    "        'neuron_group': G,\n",
    "        'input_group': P,\n",
    "        'synapses': S,\n",
    "        'rate_array': rate_array\n",
    "    }\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_supervised_model(model, tfidf_matrix, labels, sim_time=50*ms):\n",
    "    for document_vector, label in zip(tfidf_matrix, labels):\n",
    "        model['rate_array'].values = document_vector.reshape((1, -1)) * Hz\n",
    "        model['synapses'].target = label\n",
    "        run(sim_time)\n",
    "\n",
    "def predict(model, tfidf_vector, sim_time=50*ms):\n",
    "    model['rate_array'].values = tfidf_vector.reshape((1, -1)) * Hz\n",
    "    run(sim_time)\n",
    "\n",
    "    spike_counts = [sum(model['neuron_group'].v[i] > model['neuron_group'].vt) for i in range(model['neuron_group'].N)]\n",
    "    predicted_class = np.argmax(spike_counts)\n",
    "\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Equations of type 'parameter' cannot have a flag 'constant over runs', only the following flags are allowed: ['constant', 'shared']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_supervised_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[92], line 38\u001b[0m, in \u001b[0;36minitialize_supervised_model\u001b[0;34m(n_features, n_classes)\u001b[0m\n\u001b[1;32m     35\u001b[0m P \u001b[38;5;241m=\u001b[39m PoissonGroup(n_features, rates\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrate_array(t, i)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Synapses with reward-modulated STDP\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m S \u001b[38;5;241m=\u001b[39m \u001b[43mSynapses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250;43m             \u001b[39;49m\u001b[38;5;124;43;03m'''\u001b[39;49;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;43;03m             w : 1\u001b[39;49;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;43;03m             dapre/dt = -apre/tau_pre : 1 (event-driven)\u001b[39;49;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;43;03m             dapost/dt = -apost/tau_post : 1 (event-driven)\u001b[39;49;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;43;03m             target : integer (constant over runs)\u001b[39;49;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;43;03m             '''\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m             \u001b[49m\u001b[43mon_pre\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'''\u001b[39;49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;43m             I_post += w * mV\u001b[39;49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;43m             apre += A_pre\u001b[39;49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;43m             w = clip(w + (target == i_post) * A_post, w_min, w_max)\u001b[39;49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;43m             \u001b[39;49m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m             \u001b[49m\u001b[43mon_post\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'''\u001b[39;49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;43m             apost += A_post\u001b[39;49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;43m             w = clip(w + (target == i_post) * A_pre, w_min, w_max)\u001b[39;49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;43m             \u001b[39;49m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m S\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[1;32m     55\u001b[0m S\u001b[38;5;241m.\u001b[39mw \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrand() * w_max\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/brian2/synapses/synapses.py:853\u001b[0m, in \u001b[0;36mSynapses.__init__\u001b[0;34m(self, source, target, model, on_pre, pre, on_post, post, connect, delay, on_event, multisynaptic_index, namespace, dtype, codeobj_class, dt, clock, order, method, method_options, name)\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel has to be a string or an Equations \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    849\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject, is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    850\u001b[0m     )\n\u001b[1;32m    852\u001b[0m \u001b[38;5;66;03m# Check flags\u001b[39;00m\n\u001b[0;32m--> 853\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_flags\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mDIFFERENTIAL_EQUATION\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevent-driven\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclock-driven\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mSUBEXPRESSION\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msummed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshared\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconstant over dt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m        \u001b[49m\u001b[43mPARAMETER\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconstant\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshared\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mincompatible_flags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevent-driven\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclock-driven\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 'summed' cannot be combined with\u001b[39;49;00m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# any other flag\u001b[39;49;00m\n\u001b[1;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msummed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshared\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconstant over dt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mj\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelay\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    868\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnames:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/brian2/equations/equations.py:1233\u001b[0m, in \u001b[0;36mEquations.check_flags\u001b[0;34m(self, allowed_flags, incompatible_flags)\u001b[0m\n\u001b[1;32m   1229\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1230\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEquations of type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00meq\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cannot have any flags.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1231\u001b[0m     )\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flag \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_flags[eq\u001b[38;5;241m.\u001b[39mtype]:\n\u001b[0;32m-> 1233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1234\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEquations of type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00meq\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cannot have a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1235\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflag \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mflag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, only the following flags \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1236\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mare allowed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mallowed_flags[eq\u001b[38;5;241m.\u001b[39mtype]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1237\u001b[0m     )\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;66;03m# Check for incompatibilities\u001b[39;00m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m flag_combinations \u001b[38;5;129;01min\u001b[39;00m incompatible_flags:\n",
      "\u001b[0;31mValueError\u001b[0m: Equations of type 'parameter' cannot have a flag 'constant over runs', only the following flags are allowed: ['constant', 'shared']"
     ]
    }
   ],
   "source": [
    "model = initialize_supervised_model(n_features=n_features, n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'rate_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_supervised_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtfidf_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[92], line 68\u001b[0m, in \u001b[0;36mtrain_supervised_model\u001b[0;34m(model, tfidf_matrix, labels, sim_time)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_supervised_model\u001b[39m(model, tfidf_matrix, labels, sim_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m\u001b[38;5;241m*\u001b[39mms):\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m document_vector, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tfidf_matrix, labels):\n\u001b[0;32m---> 68\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrate_array\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;241m=\u001b[39m document_vector\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m*\u001b[39m Hz\n\u001b[1;32m     69\u001b[0m         model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msynapses\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m label\n\u001b[1;32m     70\u001b[0m         run(sim_time)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rate_array'"
     ]
    }
   ],
   "source": [
    "train_supervised_model(model, tfidf_matrix, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines\n",
    "\n",
    "Caracter√≠sticas:\n",
    "* Embeddings\n",
    "* Conjunto de datos con preprocesamiento"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../Scripts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import embeddigs as emb\n",
    "import baseline_model as b\n",
    "import plots as p\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = '../Datasets/CSV/Clean/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English\n",
    "data_training_en_path = f'{main_path}data_training_en_lemma.csv'\n",
    "data_test_en_path = f'{main_path}data_test_en_lemma.csv'\n",
    "\n",
    "# Spanish\n",
    "data_training_es_path = f'{main_path}data_training_es_lemma.csv'\n",
    "data_test_es_path = f'{main_path}data_test_en_lemma.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English\n",
    "data_training_en = pd.read_csv(data_training_en_path).dropna()\n",
    "data_test_en = pd.read_csv(data_test_en_path).dropna()\n",
    "\n",
    "# Spanish\n",
    "data_training_es = pd.read_csv(data_training_es_path).dropna()\n",
    "data_test_es = pd.read_csv(data_test_es_path).dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "target_names = ['0', '1']\n",
    "en_wv_path = '../../../Models/Word vectors/fasttext_english_twitter_100d.vec'\n",
    "es_wv_path = '../../../Models/Word vectors/fasttext_spanish_twitter_100d.vec'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model\n",
    "lr = LogisticRegression(random_state = seed, penalty = 'l2', solver = 'liblinear', max_iter = 10000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English and Spanish\n",
    "lr_en_fake = emb.Embeddings(embedding_path=en_wv_path, \n",
    "                            is_w2v_format=True, \n",
    "                            data_train=data_training_en, \n",
    "                            data_test=data_test_en, \n",
    "                            x_label_column='tweet', \n",
    "                            y_label_column='label', \n",
    "                            ai_model=lr, \n",
    "                            target_names=target_names)\n",
    "\n",
    "lr_es_fake = emb.Embeddings(embedding_path=es_wv_path, \n",
    "                            is_w2v_format=True, \n",
    "                            data_train=data_training_es, \n",
    "                            data_test=data_test_es, \n",
    "                            x_label_column='tweet', \n",
    "                            y_label_column='label', \n",
    "                            ai_model=lr, \n",
    "                            target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings\n",
      "Sentence to tokens\n",
      "Tokens to word vectors\n",
      "Transforming train and test data\n",
      "Training model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59     10000\n",
      "           1       0.59      0.59      0.59     10000\n",
      "\n",
      "    accuracy                           0.59     20000\n",
      "   macro avg       0.59      0.59      0.59     20000\n",
      "weighted avg       0.59      0.59      0.59     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model_fake_en, lr_metrics_fake_en = lr_en_fake.word_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings\n",
      "Sentence to tokens\n",
      "Tokens to word vectors\n",
      "Transforming train and test data\n",
      "Training model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.65      0.57     10000\n",
      "           1       0.52      0.38      0.44     10000\n",
      "\n",
      "    accuracy                           0.52     20000\n",
      "   macro avg       0.52      0.52      0.51     20000\n",
      "weighted avg       0.52      0.52      0.51     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model_fake_es, lr_metrics_fake_es = lr_es_fake.word_embedding()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = CalibratedClassifierCV(LinearSVC(random_state = seed, penalty = 'l2', max_iter = 10000))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English and Spanish\n",
    "svc_en_fake = emb.Embeddings(embedding_path=en_wv_path, \n",
    "                            is_w2v_format=True, \n",
    "                            data_train=data_training_en, \n",
    "                            data_test=data_test_en, \n",
    "                            x_label_column='tweet', \n",
    "                            y_label_column='label', \n",
    "                            ai_model=svc, \n",
    "                            target_names=target_names)\n",
    "\n",
    "svc_es_fake = emb.Embeddings(embedding_path=es_wv_path, \n",
    "                            is_w2v_format=True, \n",
    "                            data_train=data_training_es, \n",
    "                            data_test=data_test_es, \n",
    "                            x_label_column='tweet', \n",
    "                            y_label_column='label', \n",
    "                            ai_model=svc, \n",
    "                            target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings\n",
      "Sentence to tokens\n",
      "Tokens to word vectors\n",
      "Transforming train and test data\n",
      "Training model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.60      0.59     10000\n",
      "           1       0.59      0.59      0.59     10000\n",
      "\n",
      "    accuracy                           0.59     20000\n",
      "   macro avg       0.59      0.59      0.59     20000\n",
      "weighted avg       0.59      0.59      0.59     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_model_fake_en, svc_metrics_fake_en = svc_en_fake.word_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings\n",
      "Sentence to tokens\n",
      "Tokens to word vectors\n",
      "Transforming train and test data\n",
      "Training model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.67      0.58     10000\n",
      "           1       0.52      0.36      0.43     10000\n",
      "\n",
      "    accuracy                           0.52     20000\n",
      "   macro avg       0.52      0.52      0.50     20000\n",
      "weighted avg       0.52      0.52      0.50     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_model_fake_es, svc_metrics_fake_es = svc_es_fake.word_embedding()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth = 100, random_state = seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English and Spanish\n",
    "rf_en_fake = emb.Embeddings(embedding_path=en_wv_path, \n",
    "                            is_w2v_format=True, \n",
    "                            data_train=data_training_en, \n",
    "                            data_test=data_test_en, \n",
    "                            x_label_column='tweet', \n",
    "                            y_label_column='label', \n",
    "                            ai_model=rf, \n",
    "                            target_names=target_names)\n",
    "\n",
    "rf_es_fake = emb.Embeddings(embedding_path=es_wv_path, \n",
    "                            is_w2v_format=True, \n",
    "                            data_train=data_training_es, \n",
    "                            data_test=data_test_es, \n",
    "                            x_label_column='tweet', \n",
    "                            y_label_column='label', \n",
    "                            ai_model=rf, \n",
    "                            target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings\n",
      "Sentence to tokens\n",
      "Tokens to word vectors\n",
      "Transforming train and test data\n",
      "Training model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.60      0.60     10000\n",
      "           1       0.61      0.62      0.61     10000\n",
      "\n",
      "    accuracy                           0.61     20000\n",
      "   macro avg       0.61      0.61      0.61     20000\n",
      "weighted avg       0.61      0.61      0.61     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model_fake_en, rf_metrics_fake_en = rf_en_fake.word_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings\n",
      "Sentence to tokens\n",
      "Tokens to word vectors\n",
      "Transforming train and test data\n",
      "Training model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.54      0.53     10000\n",
      "           1       0.53      0.51      0.52     10000\n",
      "\n",
      "    accuracy                           0.52     20000\n",
      "   macro avg       0.52      0.52      0.52     20000\n",
      "weighted avg       0.52      0.52      0.52     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model_fake_es, rf_metrics_fake_es = rf_es_fake.word_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

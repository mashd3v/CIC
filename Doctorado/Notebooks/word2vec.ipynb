{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import string"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get word embeddings from gensim API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "print(list(gensim.downloader.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============--------------------------------------] 24.2% 48.3/199.5MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================------------------------------] 40.3% 80.4/199.5MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============================----------------------] 57.2% 114.1/199.5MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 199.5/199.5MB downloaded\n"
     ]
    }
   ],
   "source": [
    "wv = api.load('glove-twitter-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model\n",
    "wv.save('../Models/glove-twitter-50.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing model\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "wv = KeyedVectors.load('../Models/Word vectors/glove-twitter-50.kv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Spanish word embeddings](https://github.com/dccuchile/spanish-word-embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing model\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "wv_file = '../Models/Word vectors/fasttext-sbwc.3.6.e20.vec'\n",
    "cantidad = 1000000\n",
    "word_vectors = KeyedVectors.load_word2vec_format(wv_file, limit=cantidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtaining vector size\n",
    "word_vectors.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.9115e-02, -3.6542e-01,  1.3958e-01, -4.2597e-01,  1.0145e-01,\n",
       "       -3.6578e-02, -1.0592e-01,  1.5053e-01, -9.0460e-02, -3.0934e-01,\n",
       "        8.7225e-02,  2.9844e-01,  2.0698e-01, -7.8273e-03,  5.6001e-01,\n",
       "       -2.3457e-02,  1.2521e-01,  2.8260e-01,  3.0854e-01,  3.4050e-01,\n",
       "       -4.8883e-01,  1.7496e-01, -1.0263e-01, -2.0962e-01,  1.6413e-02,\n",
       "       -1.9576e-01, -1.4082e-01, -3.1030e-01, -3.1040e-01, -1.5622e-01,\n",
       "        2.2372e-01, -2.0321e-01, -3.5432e-01, -9.5409e-02, -2.4276e-01,\n",
       "       -9.8966e-02,  1.9674e-01,  2.0707e-02,  5.1833e-02, -1.8641e-01,\n",
       "        4.1339e-01, -3.1974e-01, -5.0575e-01,  2.2726e-01,  3.3545e-01,\n",
       "        3.2611e-01, -6.6681e-01, -2.5831e-03,  4.0284e-01, -9.1891e-02,\n",
       "        2.7222e-01,  3.2995e-02, -7.5253e-03, -1.9250e-01, -1.1460e-01,\n",
       "       -5.0392e-01,  5.5692e-02, -1.6391e-01,  5.0486e-01,  8.4460e-02,\n",
       "       -3.8727e-01,  4.8008e-02, -1.6161e-01,  2.7881e-01,  2.1953e-01,\n",
       "        3.6075e-02, -2.5412e-03,  7.4950e-02,  2.6577e-01, -1.4575e-01,\n",
       "        7.5066e-02, -4.3823e-02, -5.6075e-01, -2.2661e-01, -1.0735e-01,\n",
       "       -1.4752e-01,  3.4733e-01,  3.5377e-02, -4.6956e-01, -7.0582e-01,\n",
       "        1.0204e-01,  2.9738e-01,  2.8710e-01, -8.9471e-02,  5.2751e-02,\n",
       "        3.9661e-01, -9.6250e-02,  9.1142e-02, -3.3657e-01, -6.5803e-02,\n",
       "       -1.1582e-01, -2.0805e-02,  4.6307e-02, -2.0907e-01, -1.0659e-01,\n",
       "       -3.9398e-01,  1.4713e-02, -8.6158e-02, -1.0654e-01,  3.1819e-01,\n",
       "        1.4323e-01,  2.3423e-01, -1.4219e-01,  1.0121e-01,  9.3398e-02,\n",
       "        3.3175e-01,  3.5769e-01,  4.9209e-02,  2.2423e-01, -7.6095e-02,\n",
       "        6.0731e-01,  1.2912e-01, -3.8166e-01, -6.9824e-02,  7.6519e-02,\n",
       "        5.1463e-02,  1.2669e-01,  2.9877e-01, -5.6162e-01,  1.3945e-01,\n",
       "       -4.2327e-02, -3.6512e-01, -4.2884e-01,  9.5416e-02, -1.4089e-01,\n",
       "        1.4130e-01, -3.7764e-01,  3.4192e-01, -2.0877e-01,  5.7289e-01,\n",
       "        1.7388e-01,  5.0181e-01,  3.1126e-01,  4.2340e-02, -8.9456e-03,\n",
       "       -1.3819e-02,  2.9145e-02, -1.9171e-02, -4.1912e-01,  5.5972e-02,\n",
       "       -3.6730e-01,  2.4609e-02, -5.6689e-01, -1.2064e-01,  4.0474e-02,\n",
       "       -3.7411e-01,  5.3561e-03, -2.0295e-01, -5.1719e-02,  1.1992e-01,\n",
       "        5.3193e-02,  1.6311e-01,  2.1519e-02,  4.3407e-01, -1.3513e-01,\n",
       "        3.1114e-01,  5.0937e-01,  4.0534e-01, -4.3503e-01, -1.6291e-01,\n",
       "        9.5590e-02, -1.2673e-01,  2.7970e-01, -1.4221e-01,  1.6050e-01,\n",
       "       -4.8588e-02,  3.6689e-01,  1.7329e-01, -4.0478e-03, -3.7803e-01,\n",
       "       -1.6006e-03, -3.2391e-01, -2.9225e-01,  2.2612e-01,  5.9043e-01,\n",
       "       -3.1471e-01, -2.3346e-02,  2.5225e-01, -2.0746e-01, -1.1266e-01,\n",
       "       -1.4736e-01, -1.0363e-01,  2.8070e-01,  1.9955e-01, -1.1405e-01,\n",
       "       -4.7337e-02, -1.6725e-01,  4.1025e-02,  3.5754e-01, -1.3979e-01,\n",
       "       -1.1757e-01, -2.2772e-02,  1.8286e-01, -1.5843e-01, -4.1395e-02,\n",
       "        1.1344e-01, -1.6498e-01, -5.4154e-01, -4.0402e-02,  2.0799e-01,\n",
       "       -1.9179e-01, -3.5754e-04, -3.6751e-01, -1.8649e-01, -4.3625e-01,\n",
       "        2.2820e-01, -3.9561e-01,  1.7734e-01,  4.4206e-02, -2.6056e-01,\n",
       "        3.0051e-01,  8.1193e-02,  3.2505e-01,  2.6334e-01, -1.6692e-01,\n",
       "       -1.2607e-02, -1.0436e-01,  1.0312e-01,  1.3281e-01, -2.4616e-02,\n",
       "       -5.0085e-02,  8.0325e-02,  9.2383e-02,  1.4025e-01,  6.9107e-01,\n",
       "        1.6132e-01, -1.2110e-01,  2.2950e-02, -8.9709e-02,  1.7607e-01,\n",
       "        4.3563e-01,  7.8420e-02,  1.7211e-01, -4.9884e-02,  1.1790e-01,\n",
       "        3.6987e-01,  1.3245e-01,  7.1086e-02, -1.0274e-01,  9.7243e-02,\n",
       "        4.2231e-02,  1.6213e-01,  7.1657e-02, -6.8299e-02,  2.6412e-01,\n",
       "       -2.2368e-01,  4.5645e-01,  1.5442e-01, -4.7769e-01,  4.5863e-03,\n",
       "       -3.3448e-01,  1.6523e-01, -2.6004e-01,  1.8050e-01,  4.5586e-02,\n",
       "        4.6367e-01, -4.8403e-02,  2.8964e-01,  3.0782e-01, -3.7580e-01,\n",
       "       -2.4969e-01, -2.1246e-01, -1.7715e-01, -4.3275e-01,  3.0599e-01,\n",
       "       -9.1958e-02, -3.4360e-01,  1.3557e-02, -1.8494e-01,  1.8835e-01,\n",
       "       -1.5545e-01, -2.8776e-01,  3.0526e-01,  1.8489e-01, -6.6247e-02,\n",
       "        1.9858e-01, -3.9738e-02, -1.1288e-01, -1.9122e-01,  1.8874e-01,\n",
       "       -5.9207e-02, -2.4464e-01,  7.8704e-02, -4.9032e-02, -4.0152e-02,\n",
       "        8.6643e-02,  4.4680e-03,  4.8261e-01, -9.5345e-02, -9.3862e-02,\n",
       "        2.2675e-01,  4.7245e-01, -1.6330e-01,  4.1357e-01,  1.2386e-01,\n",
       "        1.7891e-01,  1.3402e-01, -1.2950e-01,  1.9641e-01,  1.9061e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How word vector looks like\n",
    "word_vectors['manzana']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>tweets</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>me quise ligar a una chava ayer y no me pelo l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>papaya rockera eres un punal papayita</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>magnate ofrece mdd al hombre que conquiste a s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>los trolebuses del desgobierno de epn son idio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>en epoca de hitler no se decia eres gay y si e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index                                             tweets  label\n",
       "0           0      0  me quise ligar a una chava ayer y no me pelo l...      0\n",
       "1           1      1              papaya rockera eres un punal papayita      0\n",
       "2           2      2  magnate ofrece mdd al hombre que conquiste a s...      0\n",
       "3           3      3  los trolebuses del desgobierno de epn son idio...      0\n",
       "4           4      4  en epoca de hitler no se decia eres gay y si e...      0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../Hate speech/Competitions/HOMO-Mex/Datasets/Clean datasets/homomex_training.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_vector(sentence, word_vector):\n",
    "    vector_size = word_vector.vector_size\n",
    "    wv_res = np.zeros(vector_size)\n",
    "    ctr = 1\n",
    "    \n",
    "    for word in sentence:\n",
    "        if word in word_vector:\n",
    "            ctr += 1\n",
    "            wv_res += word_vector[word]\n",
    "    \n",
    "    wv_res = wv_res / ctr\n",
    "    return wv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    tokens = sentence.split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokens'] = data['tweets'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>tweets</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>me quise ligar a una chava ayer y no me pelo l...</td>\n",
       "      <td>0</td>\n",
       "      <td>[me, quise, ligar, a, una, chava, ayer, y, no,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>papaya rockera eres un punal papayita</td>\n",
       "      <td>0</td>\n",
       "      <td>[papaya, rockera, eres, un, punal, papayita]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>magnate ofrece mdd al hombre que conquiste a s...</td>\n",
       "      <td>0</td>\n",
       "      <td>[magnate, ofrece, mdd, al, hombre, que, conqui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>los trolebuses del desgobierno de epn son idio...</td>\n",
       "      <td>0</td>\n",
       "      <td>[los, trolebuses, del, desgobierno, de, epn, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>en epoca de hitler no se decia eres gay y si e...</td>\n",
       "      <td>0</td>\n",
       "      <td>[en, epoca, de, hitler, no, se, decia, eres, g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index                                             tweets  \\\n",
       "0           0      0  me quise ligar a una chava ayer y no me pelo l...   \n",
       "1           1      1              papaya rockera eres un punal papayita   \n",
       "2           2      2  magnate ofrece mdd al hombre que conquiste a s...   \n",
       "3           3      3  los trolebuses del desgobierno de epn son idio...   \n",
       "4           4      4  en epoca de hitler no se decia eres gay y si e...   \n",
       "\n",
       "   label                                             tokens  \n",
       "0      0  [me, quise, ligar, a, una, chava, ayer, y, no,...  \n",
       "1      0       [papaya, rockera, eres, un, punal, papayita]  \n",
       "2      0  [magnate, ofrece, mdd, al, hombre, que, conqui...  \n",
       "3      0  [los, trolebuses, del, desgobierno, de, epn, s...  \n",
       "4      0  [en, epoca, de, hitler, no, se, decia, eres, g...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['vector'] = data['tokens'].apply(sentence_vector, word_vector=word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>tweets</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>me quise ligar a una chava ayer y no me pelo l...</td>\n",
       "      <td>0</td>\n",
       "      <td>[me, quise, ligar, a, una, chava, ayer, y, no,...</td>\n",
       "      <td>[-0.023403286235406995, -0.21893383166752756, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>papaya rockera eres un punal papayita</td>\n",
       "      <td>0</td>\n",
       "      <td>[papaya, rockera, eres, un, punal, papayita]</td>\n",
       "      <td>[0.08454919755458831, -0.24837599992752074, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>magnate ofrece mdd al hombre que conquiste a s...</td>\n",
       "      <td>0</td>\n",
       "      <td>[magnate, ofrece, mdd, al, hombre, que, conqui...</td>\n",
       "      <td>[-0.031890837905498653, -0.2504725396060027, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>los trolebuses del desgobierno de epn son idio...</td>\n",
       "      <td>0</td>\n",
       "      <td>[los, trolebuses, del, desgobierno, de, epn, s...</td>\n",
       "      <td>[-0.0025017298041627957, -0.2020074220087666, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>en epoca de hitler no se decia eres gay y si e...</td>\n",
       "      <td>0</td>\n",
       "      <td>[en, epoca, de, hitler, no, se, decia, eres, g...</td>\n",
       "      <td>[-0.024634997981290024, -0.19469095844154558, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index                                             tweets  \\\n",
       "0           0      0  me quise ligar a una chava ayer y no me pelo l...   \n",
       "1           1      1              papaya rockera eres un punal papayita   \n",
       "2           2      2  magnate ofrece mdd al hombre que conquiste a s...   \n",
       "3           3      3  los trolebuses del desgobierno de epn son idio...   \n",
       "4           4      4  en epoca de hitler no se decia eres gay y si e...   \n",
       "\n",
       "   label                                             tokens  \\\n",
       "0      0  [me, quise, ligar, a, una, chava, ayer, y, no,...   \n",
       "1      0       [papaya, rockera, eres, un, punal, papayita]   \n",
       "2      0  [magnate, ofrece, mdd, al, hombre, que, conqui...   \n",
       "3      0  [los, trolebuses, del, desgobierno, de, epn, s...   \n",
       "4      0  [en, epoca, de, hitler, no, se, decia, eres, g...   \n",
       "\n",
       "                                              vector  \n",
       "0  [-0.023403286235406995, -0.21893383166752756, ...  \n",
       "1  [0.08454919755458831, -0.24837599992752074, -0...  \n",
       "2  [-0.031890837905498653, -0.2504725396060027, -...  \n",
       "3  [-0.0025017298041627957, -0.2020074220087666, ...  \n",
       "4  [-0.024634997981290024, -0.19469095844154558, ...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['vector'].to_list()\n",
    "y = data['label'].to_list()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "model = LogisticRegression(random_state = seed, \n",
    "                            penalty = 'l2', \n",
    "                            solver = 'liblinear', \n",
    "                            max_iter = 1000)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, \n",
    "                                                  y, \n",
    "                                                  test_size=0.1, \n",
    "                                                  random_state=seed)\n",
    "target_names = ['LGBT+phobic (P)', 'Not LGBT+phobic (NP)', 'Not LGBT+related (NR)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "      LGBT+phobic (P)       0.74      0.31      0.44        94\n",
      " Not LGBT+phobic (NP)       0.83      0.92      0.87       432\n",
      "Not LGBT+related (NR)       0.75      0.79      0.77       174\n",
      "\n",
      "             accuracy                           0.80       700\n",
      "            macro avg       0.77      0.67      0.69       700\n",
      "         weighted avg       0.80      0.80      0.79       700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_val, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

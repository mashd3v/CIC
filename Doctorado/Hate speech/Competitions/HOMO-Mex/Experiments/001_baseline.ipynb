{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../../Scripts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/mash/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import text_preprocessing_v2 as tp2\n",
    "import cleaning_twitter_data as ctd\n",
    "import baseline_model as base\n",
    "import pandas as pd, numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training_path = '../Datasets/homomex_training.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_training_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [data]\n",
    "columns = ['tweets']\n",
    "dictionary_list = [{'P': 0, 'NP': 1, 'NR': 2}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = ctd.CleaningTwitterData(csv_path=data_training_path,\n",
    "                                text_column='tweets', \n",
    "                                language='spanish', \n",
    "                                remove_stopwords=False, \n",
    "                                is_dataframe=True, \n",
    "                                emoji_path=None, \n",
    "                                dataframes=dataframes, \n",
    "                                columns=columns, \n",
    "                                dictionary_list=dictionary_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = clean.clean_twitter_data(csv_path=data_training_path,\n",
    "                                text_column='tweets', \n",
    "                                language='spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.label = data.label.fillna('NR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.label.replace(list(dictionary_list[0].keys()), \n",
    "            list(dictionary_list[0].values()), \n",
    "            inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../Datasets/Clean datasets/homomex_training.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "model = LogisticRegression(random_state = seed, \n",
    "                            penalty = 'l2', \n",
    "                            solver = 'liblinear', \n",
    "                            max_iter = 1000)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data.tweets, \n",
    "                                                  data.label, \n",
    "                                                  test_size=0.05, \n",
    "                                                  random_state=seed)\n",
    "target_names = ['LGBT+phobic (P)', 'Not LGBT+phobic (NP)', 'Not LGBT+related (NR)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = {'tweets': X_train.tolist(),\n",
    "              'label': y_train.tolist()}\n",
    "val_data = {'tweets': X_val.tolist(),\n",
    "              'label': y_val.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.DataFrame(training_data, columns=['tweets', 'label'])\n",
    "val_data = pd.DataFrame(val_data, columns=['tweets', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1    4145\n",
       " 2    1689\n",
       " 0     816\n",
       " Name: label, dtype: int64,\n",
       " 1    215\n",
       " 2     89\n",
       " 0     46\n",
       " Name: label, dtype: int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.label.value_counts(), val_data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = base.Baseline(train_data=training_data, \n",
    "                  test_data=val_data, \n",
    "                  x_label_column='tweets', \n",
    "                  y_label_column='label', \n",
    "                  target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting label model\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "      LGBT+phobic (P)       0.70      0.30      0.42        46\n",
      " Not LGBT+phobic (NP)       0.80      0.92      0.86       215\n",
      "Not LGBT+related (NR)       0.78      0.73      0.76        89\n",
      "\n",
      "             accuracy                           0.79       350\n",
      "            macro avg       0.76      0.65      0.68       350\n",
      "         weighted avg       0.78      0.79      0.77       350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = b.baseline(model=model, \n",
    "                               train_data=training_data, \n",
    "                               test_data=val_data, \n",
    "                               x_label_column='tweets', \n",
    "                               y_label_column='label', \n",
    "                               target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
